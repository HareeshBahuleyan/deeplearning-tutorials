{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "np.random.seed(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'data/snli_sentences_100k.txt'\n",
    "with open(file_path, 'r') as f:\n",
    "    snli_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a smiling woman with a black smear across her face holds an umbrella.\\n',\n",
       " 'a woman walks through a bad neighborhood.\\n',\n",
       " 'a passenger jet lands on a black runway.\\n',\n",
       " 'a woman weaves cloth.\\n',\n",
       " 'a man with a yellow hat on is leaning on a wall of some sort.\\n',\n",
       " 'two little blond girls twirl their hair.\\n',\n",
       " 'a man of asian descent wearing red is leaning over another man of asian descent wearing blue who has fallen on the grass in the park on a sunny day.\\n',\n",
       " 'the two dogs are looking at each other.\\n',\n",
       " 'there are two guys partying.\\n',\n",
       " 'the photographer is shooting the models on a ledge\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of sentences = 100000\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Number of sentences = {}'.format(len(snli_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to pre-process the original data by converting to lower case, remove numbers, special character, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a smiling woman with a black smear across her face holds an umbrella.',\n",
       " 'a woman walks through a bad neighborhood.',\n",
       " 'a passenger jet lands on a black runway.',\n",
       " 'a woman weaves cloth.',\n",
       " 'a man with a yellow hat on is leaning on a wall of some sort.',\n",
       " 'two little blond girls twirl their hair.',\n",
       " 'a man of asian descent wearing red is leaning over another man of asian descent wearing blue who has fallen on the grass in the park on a sunny day.',\n",
       " 'the two dogs are looking at each other.',\n",
       " 'there are two guys partying.',\n",
       " 'the photographer is shooting the models on a ledge']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [s.strip() for s in snli_data]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [word_tokenize(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['three',\n",
       "  'people',\n",
       "  'are',\n",
       "  'looking',\n",
       "  'at',\n",
       "  'merchandise',\n",
       "  'of',\n",
       "  'a',\n",
       "  'jewelry',\n",
       "  'kiosk',\n",
       "  '.'],\n",
       " ['children', 'play', 'at', 'the', 'park']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 88 ms, total: 1min 37s\n",
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v_model = gensim.models.Word2Vec(\n",
    "    sentences,\n",
    "    size=300, # Dimension of the word embedding\n",
    "    window=2, # The maximum distance between the current and predicted word within a sentence.\n",
    "    min_count=1, # Ignores all words with total frequency lower than this.\n",
    "    sg=1, # If 1, skip-gram is employed; otherwise, CBOW is used.\n",
    "    negative=10, # Number of negative samples to be drawn\n",
    "    iter=20, # Number of epochs over the corpus\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model.save('data/w2v_300d_snli_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
